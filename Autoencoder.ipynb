{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:25.227286Z",
     "start_time": "2020-10-29T08:28:24.457373Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import meshio\n",
    "import os\n",
    "import time\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0.006, 0.0135, (0.0135-0.006)/300)\n",
    "y = np.arange(0, 0.0025, 0.0025/75)\n",
    "\n",
    "data_path = './Data'\n",
    "path_sep = '\\\\' # use '/' for Unix and '\\\\' for Windows\n",
    "folders = os.listdir(data_path)\n",
    "        \n",
    "subfolder = []\n",
    "path = []\n",
    "names = []\n",
    "condition = []\n",
    "\n",
    "for i in folders:\n",
    "    if os.path.isdir(data_path + path_sep + i): \n",
    "        subfolder.append(data_path + path_sep + i)\n",
    "\n",
    "for folder in subfolder:\n",
    "    files = os.listdir(folder + path_sep)\n",
    "    for i in files:\n",
    "        ext = os.path.splitext(i)\n",
    "        if (ext[-1].lower() == '.vtk') & (ext[0][-2] != '_'):\n",
    "            names.append(ext[0])\n",
    "            string = ext[0].replace('ER', '').replace('Tin', '').replace('Uin', '').replace('Twall', '').split('_')[0:4]\n",
    "            var = []\n",
    "            for j in string:\n",
    "                if j == 'Adiabatic':\n",
    "                    var.append(0.)\n",
    "                else:\n",
    "                    var.append(float(j))\n",
    "            condition.append(var)\n",
    "\n",
    "Q_list = []\n",
    "for folder in subfolder:\n",
    "    files = os.listdir(folder + path_sep)\n",
    "    for counter,file in enumerate(files):\n",
    "        mesh = meshio.read(folder+ path_sep +file)\n",
    "        points = mesh.points\n",
    "        Qdot = mesh.point_data['Qdot']\n",
    "        boolArr = (points[:,1] == 0) & (points[:,0] >= 0.006)  \n",
    "        Qdot = Qdot[boolArr]\n",
    "        points = points[boolArr]\n",
    "        old_points = points[:,[0, 2]]\n",
    "        grid_x, grid_y = np.meshgrid(x, y)\n",
    "        grid_new = griddata(old_points, Qdot, (grid_x, grid_y), method='nearest')\n",
    "        Q_list.append(grid_new)\n",
    "Q_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qdot = np.array(Q_list)\n",
    "indices = [10, 88, 100]\n",
    "# OutLier\n",
    "fig, axs = plt.subplots(len(indices),1,figsize=(15, 7))\n",
    "# Equivalence ratio (1.0)\n",
    "# Temperature (460)\n",
    "# Velocity (0.50 m/s)\n",
    "# Wall Temperature (373 or None)\n",
    "for idx, i in enumerate(indices):\n",
    "    img = Qdot[i]\n",
    "    axs[idx].imshow(img)\n",
    "    # axs[idx].set_title(f'Equivalence ratio: {condition[i][0] * 0.001:.2f} '\n",
    "    #                    f'Temperature: {condition[i][1]} '\n",
    "    #                    f'Velocity: {condition[i][2] * 0.01:.2f} '\n",
    "    #                    f'Wall Temperature: {condition[i][3]}')\n",
    "    axs[idx].axis('off')  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-29T08:28:27.512819Z",
     "start_time": "2020-10-29T08:28:27.353250Z"
    }
   },
   "outputs": [],
   "source": [
    "Qdot = np.delete(Qdot, indices, axis=0)\n",
    "condition = np.delete(condition, indices, axis=0)\n",
    "\n",
    "# Data Normalization\n",
    "Qdot = Qdot / np.max(Qdot)\n",
    "mean = Qdot.mean(axis = 0)\n",
    "Qdot = np.reshape(Qdot, (-1, 75, 300, 1))\n",
    "\n",
    "# Label Normalization\n",
    "normaliser = []\n",
    "conditions = np.array(condition)\n",
    "df = np.zeros(conditions.shape)\n",
    "for i in range(conditions.shape[1]):\n",
    "    df[:,i] = conditions[:,i] / np.max(conditions[:,i])\n",
    "    normaliser.append(np.max(conditions[:,i]))\n",
    "\n",
    "# Data split\n",
    "train_data, test_data, label_train, label_test = train_test_split(Qdot, df, test_size = 0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    width_shift_range=0.05, \n",
    "    height_shift_range=0.05,     \n",
    "    zoom_range=0.1,   \n",
    "    fill_mode='nearest'  \n",
    ")\n",
    "\n",
    "train_data_augmented = []\n",
    "label_train_augmented = []\n",
    "for i in range(train_data.shape[0]):\n",
    "    img = train_data[i].reshape((1, 75, 300, 1)) \n",
    "    it = datagen.flow(img, batch_size=1)\n",
    "    \n",
    "    for _ in range(5):\n",
    "        batch = it.next()\n",
    "        train_data_augmented.append(batch[0])\n",
    "        label_train_augmented.append(label_train[i])     \n",
    "        \n",
    "train_data_augmented = np.array(train_data_augmented)\n",
    "label_train_augmented = np.array(label_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the input data\n",
    "#print out the condition data for that image as well\n",
    "for i in range(236//20):\n",
    "    fig = plt.figure(figsize=(16, 80))\n",
    "    plt.imshow(np.reshape(Qdot[i*10],(75, 300)))\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Equivalence ratio: {condition[i][0] * 0.001:.2f} '\n",
    "                       f'Temperature: {condition[i][1]} '\n",
    "                       f'Velocity: {condition[i][2] * 0.01:.2f} '\n",
    "                       f'Wall Temperature: {condition[i][3]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 40))\n",
    "columns = 6\n",
    "rows = 40\n",
    "\n",
    "for i in range(1, columns * rows):\n",
    "    img = Qdot[(i-1)]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Image {i}\")  \n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Outlier imgs: 11 89 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model define \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(ConvAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      # Input layer \n",
    "      tf.keras.layers.InputLayer(input_shape = (75,300,1)),\n",
    "      \n",
    "      # Conv layer + BatchNom + LeakyReLU + MaxPooling\n",
    "      tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(3, 3)),\n",
    "      # tf.keras.layers.Dropout(0.3),       \n",
    "      \n",
    "      # Conv layer + BatchNom + LeakyReLU + MaxPooling\n",
    "      tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(5, 5)),\n",
    "      # tf.keras.layers.Dropout(0.3),         \n",
    "      \n",
    "      # Conv layer + BatchNom + LeakyReLU + MaxPooling\n",
    "      tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(5, 5)),\n",
    "      # tf.keras.layers.Dropout(0.3),   \n",
    "          \n",
    "      # Flatten  \n",
    "      tf.keras.layers.Flatten(),\n",
    "      \n",
    "      # Fully NN --> Laten variables\n",
    "      tf.keras.layers.Dense(latent_dim)\n",
    "    ])\n",
    "    \n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape = (latent_dim,)),\n",
    "      \n",
    "      # Fully NN \n",
    "      tf.keras.layers.Dense(units = 1*4*64),\n",
    "      tf.keras.layers.Reshape(target_shape = (1,4,64)),\n",
    "      \n",
    "      # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=5, strides=5,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),     \n",
    "      \n",
    "       # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),     \n",
    "\n",
    "      # Conv layer  \n",
    "      tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=5, strides=5,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      \n",
    "      # Conv layer  \n",
    "      tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "                            \n",
    "      # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=3, strides=3, padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      \n",
    "      # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      \n",
    "      tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1,padding='same', activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "\n",
    "# CAE.encoder.summary()\n",
    "# CAE.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variantional autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder: change output to mean and log variance\n",
    "- Decoder: add loss function Kullbackâ€“Leibler divergence term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class variational_autoencoder(tf.keras.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(variational_autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    \n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      # Input layer \n",
    "      tf.keras.layers.InputLayer(input_shape = (75,300,1)),\n",
    "      \n",
    "      # Conv layer + BatchNom + LeakyReLU + MaxPooling\n",
    "      tf.keras.layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(3, 3)),\n",
    "      # tf.keras.layers.Dropout(0.3),       \n",
    "      \n",
    "      # Conv layer + BatchNom + LeakyReLU + MaxPooling\n",
    "      tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(5, 5)),\n",
    "      # tf.keras.layers.Dropout(0.3),         \n",
    "      \n",
    "      # Conv layer + BatchNom + LeakyReLU + MaxPooling\n",
    "      tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      tf.keras.layers.MaxPooling2D(pool_size=(5, 5)),\n",
    "      # tf.keras.layers.Dropout(0.3),   \n",
    "          \n",
    "      # Flatten  \n",
    "      tf.keras.layers.Flatten(),\n",
    "      \n",
    "      # Fully NN --> Laten variables\n",
    "      tf.keras.layers.Dense(latent_dim*2)\n",
    "    ])\n",
    "    \n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      tf.keras.layers.InputLayer(input_shape = (latent_dim,)),\n",
    "      \n",
    "      # Fully NN \n",
    "      tf.keras.layers.Dense(units = 1*4*64),\n",
    "      tf.keras.layers.Reshape(target_shape = (1,4,64)),\n",
    "      \n",
    "      # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=5, strides=5,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),     \n",
    "      \n",
    "       # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),     \n",
    "\n",
    "      # Conv layer  \n",
    "      tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=5, strides=5,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      \n",
    "      # Conv layer  \n",
    "      tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=5, strides=1,padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "                            \n",
    "      # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=3, strides=3, padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      \n",
    "      # Conv layer \n",
    "      tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=3, strides=1, padding='same'),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.LeakyReLU(0.2),\n",
    "      \n",
    "      tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1,padding='same', activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "  def sample(self, mean, log_var):\n",
    "      epsilon = tf.random.normal(shape=tf.shape(mean))\n",
    "      return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "  def call(self, x):\n",
    "\n",
    "      # Encode to get mean and log variance\n",
    "      z_mean_log_var = self.encoder(x)\n",
    "      z_mean, z_log_var = tf.split(z_mean_log_var, num_or_size_splits=2, axis=1)\n",
    "      \n",
    "      # Reparameterization trick to sample latent space\n",
    "      z = self.sample(z_mean, z_log_var)\n",
    "      \n",
    "      # Decode to reconstruct\n",
    "      reconstructed = self.decoder(z)\n",
    "      \n",
    "      # KL divergence loss\n",
    "      beta = 0.1\n",
    "      kl_loss = beta * (-0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))\n",
    "      # tf.print(\"KL Loss:\", tf.reduce_mean(kl_loss)) \n",
    "    \n",
    "      # Add KL divergence loss to the total loss\n",
    "      self.add_loss(tf.reduce_mean(kl_loss))  \n",
    "      \n",
    "      return reconstructed\n",
    "    \n",
    "latent_dim = 8\n",
    "VAE_aug = variational_autoencoder(latent_dim)\n",
    "VAE_aug.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy')\n",
    "\n",
    "# VAE.encoder.summary()\n",
    "# VAE.decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAE\n",
    "Clatent_dim = 8\n",
    "CAE = ConvAE(latent_dim)\n",
    "CAE.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4), loss='mse')\n",
    "hist_cae = CAE.fit(train_data, train_data,epochs=200,batch_size = 8,validation_data=(test_data, test_data))\n",
    "\n",
    "# Save model for next analyse \n",
    "CAE.save(\"Trian_5\") ##Important!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "latent_dim = 8\n",
    "AUG = ConvAE(latent_dim)\n",
    "AUG.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4), loss='mse')\n",
    "hist_cae_aug = AUG.fit(train_data_augmented, train_data_augmented,epochs=200,batch_size = 8,validation_data=(test_data, test_data))\n",
    "\n",
    "# Save model for next analyse \n",
    "AUG.save('cae_aug_bs8_lr1e-4_latent_4') ##Important!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE\n",
    "hist_vae = VAE_aug.fit(train_data_augmented, train_data_augmented, epochs=200, batch_size=8, validation_data=(test_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results CAE_aug\n",
    "loss_aug = hist_cae_aug.history['loss']\n",
    "val_loss_aug = hist_cae_aug.history['val_loss']\n",
    "\n",
    "plt.semilogy(loss_aug, label ='Train loss')\n",
    "plt.semilogy(val_loss_aug, label = 'Validation loss')\n",
    "# plt.plot(loss, label ='Train loss')\n",
    "# plt.plot(val_loss, label = 'Validation loss')\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'CAE Latent dimension: {latent_dim}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results CAE\n",
    "hist_cae = tf.keras.models.load_model(\"Models/cae/cae_aug_bs8_lr1e-4_latent8\")\n",
    "loss = hist_cae.history['loss']\n",
    "val_loss = hist_cae.history['val_loss']\n",
    "\n",
    "plt.semilogy(loss, label ='Train loss')\n",
    "plt.semilogy(val_loss, label = 'Validation loss')\n",
    "# plt.plot(loss, label ='Train loss')\n",
    "# plt.plot(val_loss, label = 'Validation loss')\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'CAE Latent dimension: {latent_dim}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results VAE\n",
    "loss = hist_vae.history['loss']\n",
    "val_loss = hist_vae.history['val_loss']\n",
    "\n",
    "plt.semilogy(loss, label ='Train loss')\n",
    "plt.semilogy(val_loss, label = 'Validation loss')\n",
    "# plt.plot(loss, label ='Train loss')\n",
    "# plt.plot(val_loss, label = 'Validation loss')\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'VAE Latent dimension: {latent_dim}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CAE Visualization\n",
    "encoded_test_cae = CAE.encoder(test_data).numpy()\n",
    "decoded_test_cae = CAE.decoder(encoded_test_cae).numpy()\n",
    "\n",
    "# loops = 9\n",
    "# images_per_loop = 4\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 4\n",
    "rows = 9\n",
    "for i in range(1, columns * rows + 1, 2):\n",
    "  img = test_data[i - 1] \n",
    "  ax = fig.add_subplot(rows, columns, i)  \n",
    "  plt.imshow(img)\n",
    "  plt.title(\"original\")\n",
    "  plt.axis('off')  \n",
    "\n",
    "  decoded_img = decoded_test_cae[i - 1]  \n",
    "  ax = fig.add_subplot(rows, columns, i + 1) \n",
    "  plt.imshow(decoded_img)\n",
    "  plt.title(\"CAE reconstructed\")\n",
    "  plt.axis('off')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG = tf.keras.models.load_model('Models/cae/cae_aug_bs8_lr1e-4_latent8') \n",
    "AUG4 = tf.keras.models.load_model('Models/cae/cae_aug_bs8_lr1e-4_latent4') \n",
    "\n",
    "encoded_cae_aug = AUG.encoder(test_data).numpy()\n",
    "decoded_cae_aug = AUG.decoder(encoded_cae_aug).numpy()\n",
    "\n",
    "encoded_cae_aug4 = AUG4.encoder(test_data).numpy()\n",
    "decoded_cae_aug4 = AUG4.decoder(encoded_cae_aug4).numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 22))  \n",
    "columns = 3\n",
    "rows = 20  \n",
    "\n",
    "for i in range(1, rows * columns + 1, 3):\n",
    "    idx = (i - 1) // 3  \n",
    "\n",
    "    # original\n",
    "    img = test_data[idx]\n",
    "    ax = fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # CAE reconstructed (latent 8)\n",
    "    decoded_img = decoded_cae_aug[idx]\n",
    "    ax = fig.add_subplot(rows, columns, i + 1)\n",
    "    plt.imshow(decoded_img)\n",
    "    plt.title(\"Latent 8\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # CAE reconstructed (latent 4)\n",
    "    decoded_img4 = decoded_cae_aug4[idx]\n",
    "    ax = fig.add_subplot(rows, columns, i + 2)\n",
    "    plt.imshow(decoded_img4)\n",
    "    plt.title(\"Latent 4\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE visualization\n",
    "# latent = autoencoder.encoder(test_data).numpy()\n",
    "encoded_test_vae = VAE_aug.encoder(test_data).numpy()\n",
    "mean_vae,log_var = tf.split(encoded_test_vae, num_or_size_splits=2, axis=1)\n",
    "decoded_test_vae = VAE_aug.decoder(VAE_aug.sample(mean_vae,log_var)).numpy()\n",
    "\n",
    "# loops = 9\n",
    "# images_per_loop = 4\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 4\n",
    "rows = 9\n",
    "for i in range(1, columns * rows + 1, 2):\n",
    "  img = test_data[i - 1] \n",
    "  ax = fig.add_subplot(rows, columns, i)  \n",
    "  plt.imshow(img)\n",
    "  plt.title(\"original\")\n",
    "  plt.axis('off')  \n",
    "\n",
    "  decoded_img = decoded_test_vae[i - 1]  \n",
    "  ax = fig.add_subplot(rows, columns, i + 1) \n",
    "  plt.imshow(decoded_img)\n",
    "  plt.title(\"VAE reconstructed\")\n",
    "  plt.axis('off')  \n",
    "\n",
    "plt.show()\n",
    "# fig, axs = plt.subplots(loops * 2, images_per_loop, figsize=(images_per_loop * 2, loops * 2))\n",
    "\n",
    "# for loop in range(loops):\n",
    "#     for i in range(images_per_loop):\n",
    "#         index = loop * images_per_loop + i\n",
    "        \n",
    "#         axs[2 * loop, i].imshow(test_data[index].squeeze())\n",
    "#         axs[2 * loop, i].axis('off')\n",
    "#         axs[2 * loop, i].set_title(\"Original\")\n",
    "\n",
    "#         axs[2 * loop + 1, i].imshow(decoded_test_vae[index].squeeze())\n",
    "#         axs[2 * loop + 1, i].axis('off')\n",
    "#         axs[2 * loop + 1, i].set_title(\"VAE Reconstructed\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dim = conditions.shape[1]\n",
    "latent_dim = 8\n",
    "num_layers = 8 \n",
    "\n",
    "mapping = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(param_dim,)) \n",
    "] + [tf.keras.layers.Dense(2**(n+2), activation='relu') for n in range(1, num_layers + 1)  \n",
    "] + [\n",
    "    tf.keras.layers.Dense(latent_dim, activation='linear')  \n",
    "])\n",
    "mapping.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')\n",
    "\n",
    "encoded_train_mapping = AUG.encoder(train_data).numpy()\n",
    "encoded_test_mapping = AUG.encoder(test_data).numpy()\n",
    "\n",
    "hist_mapping = mapping.fit(label_train, encoded_train_mapping, epochs=1000, batch_size=8,validation_data=(label_test,encoded_test_mapping))\n",
    "# mapping.save('fcnn_bs8_lr1e-4_latent_8_nlayers_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "# Prefix for model file path\n",
    "model_dir = 'Models/cae/'\n",
    "model_prefix = 'Train_'\n",
    "\n",
    "# Range of model layers\n",
    "n_counts = range(1, 7)\n",
    "\n",
    "# List to store MSE values for each model\n",
    "mse_values = []\n",
    "\n",
    "# Loop through the models and compute MSE\n",
    "for n in n_counts:\n",
    "    model_path = os.path.join(model_dir, f'{model_prefix}{n}')\n",
    "    \n",
    "    # Load model and predict\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    # Flatten the data for MSE calculation\n",
    "    test_data_flat = test_data.reshape(test_data.shape[0], -1)\n",
    "    predictions_flat = predictions.reshape(predictions.shape[0], -1)\n",
    "\n",
    "    # Compute and store MSE\n",
    "    mse = mean_squared_error(test_data_flat, predictions_flat)\n",
    "    mse_values.append(mse)\n",
    "    \n",
    "    print(f'Model with {n}. Train - MSE: {mse}')\n",
    "\n",
    "# Convert mse_values to numpy array for easier manipulation\n",
    "mse_values = np.array(mse_values)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.style.use('ggplot')\n",
    "# Plot MSE values with semilog scale, customized line style and markers\n",
    "plt.semilogy(n_counts, mse_values, marker='o', linestyle='-', color='b', markersize=10, linewidth=2)\n",
    "\n",
    "# Title and labels with font size adjustments\n",
    "plt.title('Comparison of Model MSE with different hyperparameters', fontsize=16)\n",
    "plt.xlabel('Train step', fontsize=14)\n",
    "plt.ylabel('Mean Squared Error (MSE)', fontsize=14)\n",
    "\n",
    "# Customizing tick sizes\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Grid customization\n",
    "plt.grid(True, linestyle='--', linewidth=0.7)\n",
    "\n",
    "# Add shaded region for simulated error bounds\n",
    "mse_min = mse_values * 0.9  # Lower bound\n",
    "mse_max = mse_values * 1.1  # Upper bound\n",
    "plt.fill_between(n_counts, mse_min, mse_max, color='b', alpha=0.2)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fcnn4 = tf.keras.models.load_model(\"Models/fcnn/fcnn_bs8_lr1e-4_latent_4_nlayers_8\")\n",
    "# fcnn8 = tf.keras.models.load_model(\"Models/fcnn/fcnn_bs8_lr1e-4_latent_8_nlayers_8\")\n",
    "\n",
    "\n",
    "loss_map = hist_mapping.history['loss']\n",
    "val_loss_map = hist_mapping.history['val_loss']\n",
    "\n",
    "# plt.semilogy(loss_map, label ='Train loss')\n",
    "# plt.semilogy(val_loss_map, label = 'Validation loss')\n",
    "plt.plot(loss_map, label ='Train loss')\n",
    "plt.plot(val_loss_map, label = 'Validation loss')\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'FCNN Latent dimention: {latent_dim}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcnn = tf.keras.models.load_model(\"Models/fcnn/fcnn_bs8_lr1e-4_latent_8_nlayers_8\")\n",
    "fcnn4 = tf.keras.models.load_model(\"Models/fcnn/fcnn_bs8_lr1e-4_latent_4_nlayers_8\")\n",
    "\n",
    "idx = 137\n",
    "# try 19, 32, 100, 170, 230\n",
    "\n",
    "# Select parameters for the specific index\n",
    "new_params = df[idx]\n",
    "params = np.expand_dims(new_params, axis=0)\n",
    "\n",
    "# Get the latent data and decoded images from latent dimensions 8 and 4\n",
    "latent_data_8 = fcnn(params)  # Assuming this is for latent dimension 8\n",
    "pred_img_8 = (AUG.decoder(latent_data_8)).numpy()\n",
    "\n",
    "latent_data_4 = fcnn4(params)  # Assuming this is for latent dimension 4\n",
    "pred_img_4 = (AUG4.decoder(latent_data_4)).numpy()\n",
    "\n",
    "# Plot the original, latent 8 and latent 4 decoded images\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot original image in the first row\n",
    "img = Qdot[idx]\n",
    "# Row 1: Original image\n",
    "ax = fig.add_subplot(3, 1, 1)\n",
    "plt.imshow(np.squeeze(img))\n",
    "plt.axis('off')\n",
    "plt.title(f'Equivalence ratio: {condition[idx][0] * 0.001:.2f} '\n",
    "                       f'Temperature: {condition[idx][1]} '\n",
    "                       f'Velocity: {condition[idx][2] * 0.01:.2f} '\n",
    "                       f'Wall Temperature: {condition[idx][3]}')\n",
    "# Row 2: Latent 8 image\n",
    "ax = fig.add_subplot(3, 1, 2)\n",
    "plt.imshow(np.squeeze(pred_img_8))\n",
    "plt.axis('off')\n",
    "# plt.title(\"Predicted Image from Latent 8\", pad=10)\n",
    "\n",
    "# Row 3: Latent 4 image\n",
    "ax = fig.add_subplot(3, 1, 3)\n",
    "plt.imshow(np.squeeze(pred_img_4))\n",
    "plt.axis('off')\n",
    "# plt.title(\"Predicted Image from Latent 4\", pad=10)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
